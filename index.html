<!DOCTYPE html>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <!-- Google tag (gtag.js) -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-SC6X1YW1BH"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-SC6X1YW1BH');
    </script>
    
    <script async="" src="./website_files/js"></script>
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:400italic,600italic,700italic,400,600,700" rel="stylesheet" type="text/css">

    
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Angelina Wang</title>

    <link href="./website_files/css" rel="stylesheet" type="text/css">
    <link href="./website_files/bootstrap.min.css" rel="stylesheet">
    <link href="./website_files/homepage.css" rel="stylesheet" type="text/css">

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->

  </head>
  <body>

    <div class="container">
      <header>
        <div class="row">
          <div class="col-md-4 d-flex align-items-center justify-content-md-start justify-content-center">
              <div class="profile_pic">
                  <img src="./website_files/headshot.jpeg">                                    
              </div>
          </div>

                        

          <div class="col-md-8 d-flex align-items-center">
            <div>
                  <h1>Angelina Wang</h1>
                  <p><span style="color:white;">_____________________________________________________________________</span></p>
                  <p class="affil">
                    Assistant Professor<br>Cornell Tech                   
                  </p>
                  <p>
                      <a href="pubs.html">Publications</a> |
                      <a href="teaching.html">Teaching</a> |
                      <a href="group.html">Group</a> |
                      <!-- <a href="lab.html">Lab</a> | -->
                      <a href="https://angelina-wang.github.io/files/cv.pdf" target="_blank">CV</a>
                      <!-- <a href="https://angelina-wang.github.io/files/bio.txt" target="_blank">bio</a> | -->
                      <!-- <a href="https://x.com/ang3linawang" target="_blank">twitter</a> | -->
                      <!-- <a href="https://github.com" target="_blank">github</a> | -->
                      <!-- <a href="https://scholar.google.com/citations?user=cGemfcYAAAAJ&hl=en" target="_blank">google scholar</a></p> -->
            </div>
          </div>
        </div>
<div class="col-md-4 d-flex align-items-center justify-content-md-start justify-content-center">
                    
                      <div class="col-xs-3">
<a href="mailto:angelina.wang@cornell.edu" title="email"><img src="./files/email.jpeg" style="max-height:31px;" class="img-responsive"></a>
</div>
<!-- <div class="col-xs-3">
<a href="https://x.com/ang3linawang" title="twitter"><img src="./files/twitter.png" style="max-height:31px;" class="img-responsive"></a>
</div> -->
<div class="col-xs-3">
<a href="https://bsky.app/profile/angelinawang.bsky.social" title="bluesky"><img src="./files/bluesky.png" style="max-height:31px;" class="img-responsive"></a>
</div>
 <div class="col-xs-3">
<a href="https://scholar.google.com/citations?user=cGemfcYAAAAJ&hl=en" title="google scholar"><img src="./files/scholar.png" style="max-height:31px;" class="img-responsive"></a>
</div>
</div>

        </header>
        <div class="row">
            <div class="col-md-12">

                <div id="content">
                  <div class="content-block">
                    <br>
                    <p>                      
                      I am an Assistant Professor at <a href="https://tech.cornell.edu/">Cornell Tech</a> and in the Department of <a href="https://infosci.cornell.edu/">Information Science at Cornell University</a>, as well as a field faculty member in Computer Science and Data Science. 
                      <br><br>

                      <strong>I am currently recruiting both PhD students and postdocs.</strong> If you are an interested PhD student, please apply directly to either the <a href="https://infosci.cornell.edu/phd/admissions">Cornell Information Science</a> or <a href="https://www.cs.cornell.edu/phd">Cornell Computer Science</a> PhD programs and list my name on your application. Read <a href=contact.html>this</a> for more information.
                    </p>
                    <p>
                      My research is on <strong>responsible AI</strong>. My <a href="https://angelina-wang.github.io/files/research_statement.pdf">research statement</a> (Spring 2024). Some themes I am interested in include:

    <details class="fairness">
      <summary><strong>AI fairness</strong> 
        (<a href="https://arxiv.org/abs/2205.04610">FAccT 2022</a>, 
        <a href="https://arxiv.org/abs/2303.06167">ICCV 2023</a> 
        <span style="background-color: #f8d7da; color: #721c24; padding: 2px 6px; border-radius: 4px; font-size: 0.85em;">oral</span>, 
        <a href="https://www.pnas.org/doi/10.1073/pnas.2416228122">PNAS 2025</a>, 
        <a href="https://arxiv.org/abs/2505.04038">FAccT 2025</a>, 
        <a href="https://arxiv.org/abs/2502.01926">ACL 2025</a> 
        <span style="background-color: #d4edda; color: #155724; padding: 2px 6px; border-radius: 4px; font-size: 0.85em;">best paper</span>):
      How can we move beyond one-size-fits-all, mathematically convenient notions of fairness while still being tractable?</summary> <div style="line-height:0.5em;">&nbsp;</div>
      <p style="margin-left: 2em;">We expand the frame of technical approaches which often oversimplify social concepts through mathematically convenient but harmful abstractions, e.g., treating intersectionality as a problem of simply multiple groups (<a href="https://arxiv.org/abs/2205.04610">FAccT 2022</a>), operationalizing fairness by treating all groups the same (<a href="https://arxiv.org/abs/2502.01926">ACL 2025</a> <span style="background-color: #d4edda; color: #155724; padding: 2px 6px; border-radius: 4px; font-size: 0.85em;">best paper</span>), and treating racism and sexism as symmetrical forms of oppression (<a href="https://arxiv.org/abs/2505.04038">FAccT 2025</a>). In doing so, we keep practical constraints in mind to propose tractable fine-tuning interventions (<a href="https://arxiv.org/abs/2303.06167">ICCV 2023</a> <span style="background-color: #f8d7da; color: #721c24; padding: 2px 6px; border-radius: 4px; font-size: 0.85em;">oral</span>) and bias measurements (<a href="https://www.pnas.org/doi/10.1073/pnas.2416228122">PNAS 2025</a>).</p>
    </details><div style="line-height:0.5em;">&nbsp;</div>

<script>
  document.querySelectorAll("details.fairness").forEach(d => {
    const summary = d.querySelector("summary");
    const text = summary.textContent.trim();

    d.addEventListener("toggle", () => {
      if (d.open) {
        summary.innerHTML = "<strong>AI fairness</strong>: How can we move beyond one-size-fits-all, mathematically convenient notions of fairness while still being tractable?";
      } else {
        
        summary.innerHTML = '<strong>AI fairness</strong> (<a href="https://arxiv.org/abs/2205.04610">FAccT 2022</a>, <a href="https://arxiv.org/abs/2303.06167">ICCV 2023</a> <span style="background-color: #f8d7da; color: #721c24; padding: 2px 6px; border-radius: 4px; font-size: 0.85em;">oral</span>, <a href="https://www.pnas.org/doi/10.1073/pnas.2416228122">PNAS 2025</a>, <a href="https://arxiv.org/abs/2505.04038">FAccT 2025</a>, <a href="https://arxiv.org/abs/2502.01926">ACL 2025</a> <span style="background-color: #d4edda; color: #155724; padding: 2px 6px; border-radius: 4px; font-size: 0.85em;">best paper</span>): How can we move beyond one-size-fits-all, mathematically convenient notions of fairness while still being tractable?';
      }
    });
  });
</script>

    <details class="evaluation">
      <summary><strong>Evaluation</strong> (<a href="https://arxiv.org/abs/2102.12594">ICML 2021</a>, 
        <a href="https://www.cell.com/patterns/fulltext/S2666-3899(24)00239-3">Patterns 2024</a>, 
        <a href="https://arxiv.org/abs/2502.00561">ICML Position 2025</a>, <a href="https://arxiv.org/abs/2505.10573">Preprint 2025</a>): How can we measure multi-faceted constructs in generative AI, like reasoning and fairness, and grapple with the trade-offs between incommensurate values?</summary> <div style="line-height:0.5em;">&nbsp;</div>
        <p style="margin-left: 2em;">Benchmarks and leaderboards shape the norms and goals of a field, and what we choose to measure sets our priorities (<a href="https://arxiv.org/abs/2102.12594">ICML 2021</a>). Instead of relying on single numbers from leaderboards to capture abstract constructs on open-ended generative models such as reasoning and fairness (<a href="https://www.cell.com/patterns/fulltext/S2666-3899(24)00239-3">Patterns 2024</a>), we should use multi-faceted measurements and  a more rigorous lens of validity and measurement theory (<a href="https://arxiv.org/abs/2502.00561">ICML Position 2025</a>, <a href="https://arxiv.org/abs/2505.10573">Preprint 2025</a>)</p>
    </details><div style="line-height:0.5em;">&nbsp;</div>

<script>
  document.querySelectorAll("details.evaluation").forEach(d => {
    const summary = d.querySelector("summary");
    const text = summary.textContent.trim();

    d.addEventListener("toggle", () => {
      if (d.open) {
        summary.innerHTML = "<strong>Evaluation</strong>: How can we measure multi-faceted constructs in generative AI, like reasoning and fairness, and grapple with the trade-offs between incommensurate values?";
      } else {
        
        summary.innerHTML = '<strong>Evaluation</strong> (<a href="https://arxiv.org/abs/2102.12594">ICML 2021</a>, <a href="https://www.cell.com/patterns/fulltext/S2666-3899(24)00239-3">Patterns 2024</a>, <a href="https://arxiv.org/abs/2502.00561">ICML Position 2025</a>, <a href="https://arxiv.org/abs/2505.10573">Preprint 2025</a>): How can we measure multi-faceted constructs in generative AI, like reasoning and fairness, and grapple with the trade-offs between incommensurate values?';
      }
    });
  });
</script>


    <details class="impacts">
      <summary><strong>Societal impacts of AI</strong>
        (<a href="https://dl.acm.org/doi/full/10.1145/3636509">JRC 2023</a>, 
        <a href="https://www.nature.com/articles/s42256-025-00986-z">Nature Machine Intelligence 2025</a>): What are the effects of AI on aspects of humanity such as our information ecosystem and power asymmetries?</summary><div style="line-height:0.5em;">&nbsp;</div>
        <p style="margin-left: 2em;">As AI is increasingly deployed, some common use cases such as predicting future outcomes about individuals (<a href="https://dl.acm.org/doi/full/10.1145/3636509">JRC 2023</a>) and simulating human participants with LLMs (<a href="https://www.nature.com/articles/s42256-025-00986-z">Nature Machine Intelligence 2025</a>) pose distinct normative concerns. I am especially interested in the epistemic effects of AI when we use it in domains like communication and science.</p>
    </details>

<script>
  document.querySelectorAll("details.impacts").forEach(d => {
    const summary = d.querySelector("summary");
    const text = summary.textContent.trim();

    d.addEventListener("toggle", () => {
      if (d.open) {
        summary.innerHTML = "<strong>Societal impacts of AI</strong>: What are the effects of AI on aspects of humanity such as our information ecosystem and power asymmetries?";
      } else {
        
        summary.innerHTML = '<strong>Societal impacts of AI</strong> (<a href="https://dl.acm.org/doi/full/10.1145/3636509">JRC 2023</a>, <a href="https://www.nature.com/articles/s42256-025-00986-z">Nature Machine Intelligence 2025</a>): What are the effects of AI on aspects of humanity such as our information ecosystem and power asymmetries?';
      }
    });
  });
</script>
<br>
                      <p>My work has been covered by outlets like <a href="https://www.technologyreview.com/2025/03/11/1113000/these-new-ai-benchmarks-could-help-make-models-less-biased/">MIT Technology Review</a>, <a href="https://www.vice.com/en/article/wxnaqz/ai-isnt-artificial-or-intelligent">Vice</a>, <a href="https://www.washingtonpost.com/outlook/trumps-campaign-lures-donors-with-absurd-financial-promises--and-insults/2020/10/09/ff3ea62c-08ef-11eb-9be6-cf25fb429f1a_story.html">Washington Post</a>, <a href="https://www.newscientist.com/article/2468628-why-ai-resorts-to-stereotypes-when-it-is-role-playing-humans/">New Scientist</a>, and <a href="https://www.emergingtechbrew.com/stories/2025/02/14/stanford-researchers-ai-models-bias">Tech Brew</a>.
                    </p>
                    <p>
                    <!-- I completed my PhD in Computer Science at Princeton University, advised by <a href="https://www.cs.princeton.edu/~olgarus/">Olga Russakovsky</a>. I received the <a href="https://www.nsfgrfp.org/">NSF GRFP</a>, <a href="https://eecsrisingstars2023.cc.gatech.edu/">EECS Rising Stars</a>, <a href="https://www.siebelscholars.com/">Siebel Scholarship</a>, and <a href="https://www.microsoft.com/en-us/research/academic-program/ai-society-fellows/fellows/">Microsoft AI & Society Fellowship</a>.  -->
                     Previously, I was a postdoc at Stanford University <a href="https://hai.stanford.edu/">HAI</a>, earned my PhD in Computer Science at Princeton University advised by the wonderful <a href="https://www.cs.princeton.edu/~olgarus/">Olga Russakovsky</a>, and received a BS in Electrical Engineering and Computer Science from UC Berkeley. I've received the NSF GRFP, EECS Rising Stars, Siebel Scholarship, Microsoft AI & Society Fellowship, and have interned at Microsoft Research and Arthur AI.
                    <!-- I publish in top machine learning (ICML, AAAI), computer vision (ICCV, IJCV), interdisciplinary (Big Data & Society), and responsible computing (FAccT, JRC) venues, including spotlight and oral presentations.  -->
                  </p>
                  <br>
                   <p>
                   An <a href="https://angelina-wang.github.io/fairness_faq">FAQ</a> about algorithmic fairness.
                  </p>
                  </div>

</div>

                </div>
            </div>
        </div>

    </div>
    <script src="./website_files/bootstrap.min.js"></script>
  

</body></html>
