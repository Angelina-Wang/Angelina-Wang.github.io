<!DOCTYPE html>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <!-- Google tag (gtag.js) -->
    <script async="" src="./website_files/js"></script>
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:400italic,600italic,700italic,400,600,700" rel="stylesheet" type="text/css">

    
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Angelina Wang</title>

    <link href="./website_files/css" rel="stylesheet" type="text/css">
    <link href="./website_files/bootstrap.min.css" rel="stylesheet">
    <link href="./website_files/homepage.css" rel="stylesheet" type="text/css">

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->

  </head>
  <body>

    <div class="container">
      <header>
      	<h1>
      	Publications
      </h1>
      </header>

    </div>
    <div class="container">
<div class="row">
            <div class="col-md-12">

                <div id="content">
                  <div class="content-block">
                    <br>
        <div class="paper">
    	<a href="https://arxiv.org/abs/2402.01908">Large Language Models Cannot Replace Human Participants Because They Cannot Portray Identity Groups</a><br>
   <strong>Angelina Wang</strong>, Jamie Morgenstern, John P. Dickerson<br> 
   <em>Preprint</em>
</div>
<div class="paper">
<a href="https://dl.acm.org/doi/abs/10.1145/3630106.3659045">Visions of a Discipline: Analyzing Introductory AI Courses on YouTube</a><br>
   Severin Engelmann, Madiha Zahrah Choksi, <strong>Angelina Wang</strong>, Casey Fiesler<br>
   <em>FAccT 2024</em>
</div>
<div class="paper">
<a href="https://arxiv.org/abs/2402.04420">Measuring Machine Learning Harms from Stereotypes: Requires Understanding Who is Being Harmed by Which Errors in What Ways</a><br>
   <strong>Angelina Wang</strong>, Xuechunzi Bai, Solon Barocas, Su Lin Blodgett<br>
   <em>EAAMO 2023</em>
</div>
<div class="paper">
<a href="https://arxiv.org/abs/2303.06167">Overwriting Pretrained Bias with Finetuning Data</a><br>
   <strong>Angelina Wang</strong> and Olga Russakovsky<br>
   <em>ICCV 2023 <span style="color:tomato;">(Oral)</span></em>
</div>
<div class="paper">
<a href="https://arxiv.org/abs/2206.09191">Gender Artifacts in Visual Datasets</a><br>
   Nicole Meister*, Dora Zhao*, <strong>Angelina Wang</strong>, Vikram V. Ramaswamy, Ruth Fong, Olga Russakovsky</br>
   <em>ICCV 2023</em>
</div>
<div class="paper">
<a href="https://dl.acm.org/doi/abs/10.1145/3636509">Against Predictive Optimization: On the Legitimacy of Decision-Making Algorithms that Optimize Predictive Accuracy</a> [<a href="https://predictive-optimization.cs.princeton.edu/">website</a>]<br>
   <strong>Angelina Wang</strong>*, Sayash Kapoor*, Solon Barocas, Arvind Narayanan</br>
   <em>FAccT 2023; Journal of Responsible Computing 2023</em>
</div>
<div class="paper">
<a href="https://arxiv.org/abs/2305.01776">Taxonomizing and Measuring Representational Harms: A Look at Image Tagging</a><br>
   Jared Katzman*, <strong>Angelina Wang</strong>*, Morgan Scheuerman, Su Lin Blodgett, Kristen Laird, Hanna Wallach, Solon Barocas</br>
   <em>AAAI 2023</em>
</div>
<div class="paper">
<a href="https://journals.sagepub.com/doi/10.1177/20539517221145371">Manipulative Tactics are the Norm in Political Emails: Evidence from 100K emails from the 2020 U.S. Election Cycle</a> [<a href="https://electionemails2020.org/">website</a>]<br>
   Arunesh Mathur, <strong>Angelina Wang</strong>, Carsten Schwemmer, Maia Hamin, Brandon M. Stewart, Arvind Narayanan</br>
   <em>Big Data & Society 2023</em>
</div>
<div class="paper">
<a href="https://arxiv.org/abs/2206.07173">Measuring Representational Harms in Image Captioning
</a> [<a href="https://www.youtube.com/watch?v=WJryYsn5D3o&list=PLXA0IWa3BpHm5zXqhB9rSTJ09TiFWyMo5&index=116">4 min video</a>] [<a href="https://www.youtube.com/watch?v=P7rshiDQjDQ&list=PLXA0IWa3BpHmmS6AJN9n5Qf3ffG_eHZW0&index=116">15 min video</a>]<br>
   <strong>Angelina Wang</strong>, Solon Barocas, Kristen Laird, Hanna Wallach
</br>
   <em>FAccT 2022</em>
</div>
<div class="paper">
<a href="https://arxiv.org/abs/2205.04610">Towards Intersectionality in Machine Learning: Including More Identities, Handling Underrepresentation, and Performing Evaluation
</a> [<a href="https://www.youtube.com/watch?v=BkBdUK3JMXI&list=PLXA0IWa3BpHm5zXqhB9rSTJ09TiFWyMo5&index=118">4 min video</a>] [<a href="https://www.youtube.com/watch?v=wO-PIUAYMYQ&list=PLXA0IWa3BpHmmS6AJN9n5Qf3ffG_eHZW0&index=119">15 min video</a>]<br>
   <strong>Angelina Wang</strong>, Vikram V. Ramaswamy, Olga Russakovsky
</br>
   <em>FAccT 2022</em>
</div>
<div class="paper">
<a href="https://rdcu.be/cObwT">REVISE: A Tool for Measuring and Mitigating Bias in Visual Datasets</a><br>
   <strong>Angelina Wang</strong>, Alexander Liu, Ryan Zhang, Anat Kleiman, Leslie Kim, Dora Zhao, Iroha Shirai, Arvind Narayanan, Olga Russakovsky
</br>
   <em>IJCV 2022 (extended version of ECCV 2020 publication)</em>
</div>
<div class="paper">
<a href="https://arxiv.org/abs/2106.08503">Understanding and Evaluating Racial Biases in Image Captioning</a><br>
   Dora Zhao, <strong>Angelina Wang</strong>, Olga Russakovsky
</br>
   <em>ICCV 2021</em>
</div>
<div class="paper">
<a href="https://arxiv.org/abs/2102.12594">Directional Bias Amplification</a> [<a href="https://icml.cc/virtual/2021/poster/10553">video<a>] [<a href="https://docs.google.com/drawings/d/1Ed9L8t-ARv1e7wOMX8QbKsHpu4kqi866ywakUcRWN-k/edit?usp=sharing">poster<a>]<br>
   <strong>Angelina Wang</strong> and Olga Russakovsky
</br>
   <em>ICML 2021</em>
</div>
<div class="paper">
<a href="https://arxiv.org/abs/2102.01265">The Limits of Global Inclusion in AI Development</a><br>
   Alan Chan*, Chinasa T. Okolo*, Zachary Terner*, <strong>Angelina Wang</strong>*
</br>
   <em>AAAI 2021 Workshop on Reframing Diversity in AI <span style="color:tomato;">(Spotlight)</span></em>
</div>
<div class="paper">
<a href="https://arxiv.org/abs/2004.07999v3">REVISE: A Tool for Measuring and Mitigating Bias in Visual Datasets</a><br>
   <strong>Angelina Wang</strong>, Arvind Narayanan, Olga Russakovsky
</br>
   <em>ECCV 2020 <span style="color:tomato;">(Spotlight)</span></em>
</div>
<div class="paper">
<a href="https://arxiv.org/abs/1905.04411">Learning Robotic Manipulation through Visual Planning and Acting</a><br>
   <strong>Angelina Wang</strong>, Thanard Kurutach, Kara Liu, Pieter Abbeel, Aviv Tamar
</br>
   <em>Robotics: Science and Systems 2019</em>
</div>
<div class="paper">
<a href="https://arxiv.org/abs/1711.08534">Safer Classification by Synthesis</a><br>
   William Wang, <strong>Angelina Wang</strong>, Aviv Tamar, Xi Chen, Pieter Abbeel
</br>
   <em>NeurIPS 2017 Aligned AI Workshop</em>
</div>
    </div>
    </div>
    </div>
    <h2>Other</h2>
    <div class="paper">
<a href="https://medium.com/@angelinaaa/a-tale-of-two-conferences-facct-and-icml-2022-a9b4eaa6cf17">A Tale of Two Conferences: FAccT and ICML 2022</a>
</div>
<br><br><br><br><br><br>
    </div>
    </div>
    <script src="./website_files/bootstrap.min.js"></script>
  

</body></html>