<!DOCTYPE html>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <!-- Google tag (gtag.js) -->
        <!-- Google tag (gtag.js) -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=G-SC6X1YW1BH"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-SC6X1YW1BH');
    </script>
    
    <script async="" src="./website_files/js"></script>
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:400italic,600italic,700italic,400,600,700" rel="stylesheet" type="text/css">

    
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>Angelina Wang</title>

    <link href="./website_files/css" rel="stylesheet" type="text/css">
    <link href="./website_files/bootstrap.min.css" rel="stylesheet">
    <link href="./website_files/homepage.css" rel="stylesheet" type="text/css">

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->

      <style>
    .header {
  display: flex;
  align-items: center;
  gap: 16px;  /* controls distance between h1 and toggle */
    }

    .toggle-btn {
      cursor: pointer;
      margin-left: 10px;
      padding: 4px 10px;
      border: 1px solid #aaa;
      border-radius: 5px;
      font-size: 14px;
    }

    .active {
      background: #ddd;
    }

    .paper { margin: 5px 0; }
    .hidden { display: none; }
    .pill {
  padding: 4px 12px;
  border-radius: 12px;
  background: #eee;
  cursor: pointer;
  font-size: 14px;
  margin-left: 4px;
  transition: 0.2s;
}

.pill.active {
  background:  #3399ff;
  color: white;
}
.pill:hover {
  background: #ddd;
}
  </style>

  </head>
  <body>


    <div class="container">
      <header>
         Potentially more up-to-date list: <a href="https://scholar.google.com/citations?user=cGemfcYAAAAJ&hl=en">Google Scholar</a>
         <br>  <br>

      <div class="header">
  <h1>Publications</h1>
<!--   <div>
    <span id="btn-selected" class="toggle-btn active">Selected</span>
    <span id="btn-all" class="toggle-btn">All</span>
  </div> -->
  <div class="toggle-pills">
   <span id="btn-all" class="pill">All</span>
  <span id="btn-selected" class="pill active">Selected</span>
</div>
</div>
      <a href=index.html>&larr; Home</a>

      
      </header>
      

    </div>
    <div class="container">
<div class="row">
            <div class="col-md-12">

                <div id="content">
                  <div class="content-block">
                    <br>

 <div class="paper selected">
        <a href="https://angelina-wang.github.io/files/personalization_in_practice.pdf" target="_blank">Personalization in Practice: Mismatches Between User Preferences and Chatbot Behavior Reveal the Privacy Paradox and Discriminatory Double Binds</a><br>
   <strong>Angelina Wang</strong>, Erin Beeghly, Sanmi Koyejo*, Daniel E. Ho*<br> 
   <em>Preprint 2025</em>
</div>

 <div class="paper selected">
        <a href="https://arxiv.org/abs/2509.19364">The Inadequacy of Offline LLM Evaluations: A Need to Account for Personalization in Model Behavior</a><br>
   <strong>Angelina Wang</strong>, Daniel E. Ho*, Sanmi Koyejo*<br> 
   <em>Forthcoming at Patterns 2025</em>
</div>

 <div class="paper selected">
    	<a href="https://arxiv.org/abs/2505.10573">Measurement to Meaning: A Validity-Centered Framework for AI Evaluation</a><br>
   Olawale Salaudeen, Anka Reuel, Ahmed Ahmed, Suhana Bedi, Zachary Robertson, Sudharsan Sundar, Ben Domingue, <strong>Angelina Wang</strong>*, Sanmi Koyejo*<br> 
   <em>Preprint 2025</em>
</div>

 <div class="paper all">
        <a href="https://arxiv.org/abs/2507.05216">Bridging Prediction and Intervention Problems in Social Systems</a><br>
   Lydia T Liu, Inioluwa Deborah Raji, Angela Zhou, Luke Guerdan, Jessica Hullman, Daniel Malinsky, Bryan Wilder, Simone Zhang, Hammaad Adam, Amanda Coston, Ben Laufer, Ezinne Nwankwo, Michael Zanger-Tishler, Eli Ben-Michael, Solon Barocas, Avi Feller, Marissa Gerchick, Talia Gillis, Shion Guha, Daniel Ho, Lily Hu, Kosuke Imai, Sayash Kapoor, Joshua Loftus, Razieh Nabi, Arvind Narayanan, Ben Recht, Juan Carlos Perdomo, Matthew Salganik, Mark Sendak, Alexander Tolbert, Berk Ustun, Suresh Venkatasubramanian, <strong>Angelina Wang</strong>, Ashia Wilson<br>
   <em>Preprint 2025</em>
</div>

 <div class="paper all">
        <a href="https://arxiv.org/abs/2506.14652">Rigor in AI: Doing Rigorous AI Work Requires a Broader, Responsible AI-Informed Conception of Rigor</a><br>
   Alexandra Olteanu, Su Lin Blodgett, Agathe Balayn, <strong>Angelina Wang</strong>, Fernando Diaz, Flavio du Pin Calmon, Margaret Mitchell, Michael Ekstrand, Reuben Binns, Solon Barocas<br>
   <em>NeurIPS Position Track 2025</em>
</div>

 <div class="paper all">
        <a href="https://arxiv.org/abs/2506.17303">The California Report on Frontier AI Policy</a> [<a href="https://www.cafrontieraigov.org/">website</a>]<br>
   Rishi Bommasani, Scott R. Singer, Ruth E. Appel, Sarah Cen, A. Feder Cooper, Elena Cryst, Lindsey A. Gailmard, Ian Klaus, Meredith M. Lee, Inioluwa Deborah Raji, Anka Reuel, Drew Spence, Alexander Wan, <strong>Angelina Wang</strong>, Daniel Zhang, Daniel E. Ho, Percy Liang, Dawn Song, Joseph E. Gonzalez, Jonathan Zittrain, Jennifer Tour Chayes, Mariano-Florentino Cuellar, Li Fei-Fei<br> 
   <em>Joint California Policy Working Group on AI Frontier Models 2025</em>
</div>

 <div class="paper selected">
      <a href="https://arxiv.org/abs/2502.01926">Fairness through Difference Awareness: Measuring Desired Group Discrimination in LLMs</a> [<a href="https://hai.stanford.edu/news/ais-fairness-problem-when-treating-everyone-the-same-is-the-wrong-approach">blog</a>]<br>
   <strong>Angelina Wang</strong>, Michelle Phan, Daniel E. Ho, Sanmi Koyejo<br> 
   <em>ACL Main 2025 <span style="color:tomato;">(Best Paper)</span></em>
</div>
                      
 <div class="paper selected">
    	<a href="https://arxiv.org/abs/2505.04038">Identities are not Interchangeable: The Problem of Overgeneralization in Fair Machine Learning
</a><br>
   <strong>Angelina Wang</strong><br> 
   <em>FAccT 2025</em>
</div>
                     

 <div class="paper all">
    	<a href="https://arxiv.org/abs/2503.05336">Toward an Evaluation Science for Generative AI systems</a><br>
   Laura Weidinger, Inioluwa Deborah Raji, Hanna Wallach, Margaret Mitchell, <strong>Angelina Wang</strong>, Olawale Salaudeen, Rishi Bommasani, Deep Ganguli, Sanmi Koyejo, William Isaac<br> 
   <em>National Academy of Engineering's The Bridge 2025</em>
</div>
                      
        <div class="paper all">
    	<a href="https://arxiv.org/abs/2502.00561">Position: Evaluating Generative AI Systems is a Social Science Measurement Challenge</a><br>
   Hanna Wallach, Meera Desai, A. Feder Cooper, <strong>Angelina Wang</strong>, Chad Atalla, Solon Barocas, Su Lin Blodgett, Alexandra Chouldechova, Emily Corvi, P. Alex Dow, Jean Garcia-Gathright, Alexandra Olteanu, Nicholas Pangakis, Stefanie Reed, Emily Sheng, Dan Vann, Jennifer Wortman Vaughan, Matthew Vogel, Hannah Washington, Abigail Z. Jacobs<br> 
   <em>ICML Position Track 2025</em>
</div>
                      
        <div class="paper selected">
    	<a href="https://arxiv.org/abs/2402.01908">Large Language Models that Replace Human Participants can Harmfully Misportray and Flatten Identity Groups</a><br>
   <strong>Angelina Wang</strong>, Jamie Morgenstern, John P. Dickerson<br> 
   <em>Nature Machine Intelligence 2025</em>
</div>
<div class="paper all">
      <a href="https://arxiv.org/abs/2402.04105">Measuring Implicit Bias in Explicitly Unbiased Large Language Models</a><br>
   Xuechunzi Bai, <strong>Angelina Wang</strong>, Ilia Sucholutsky, Thomas L. Griffiths<br> 
   <em>PNAS 2025</em>
</div>

<div class="paper all">
<a href="https://arxiv.org/abs/2402.04420">Measuring Machine Learning Harms from Stereotypes Requires Understanding Who Is Harmed by Which Errors in What Ways
</a><br>
   <strong>Angelina Wang</strong>, Xuechunzi Bai, Solon Barocas, Su Lin Blodgett<br>
   <em>EAAMO 2023, FAccT 2025</em>
</div>
                      
<div class="paper selected">
      <a href="https://www.cell.com/patterns/fulltext/S2666-3899(24)00239-3">Benchmark Suites Instead of Leaderboards for Evaluating AI Fairness</a><br>
   <strong>Angelina Wang</strong>, Aaron Hertzmann, Olga Russakovsky<br> 
   <em>Patterns 2024</em>
</div>

<div class="paper all">
      <a href="https://arxiv.org/abs/2405.03855">Strategies for Increasing Corporate Responsible AI Prioritization</a><br>
   <strong>Angelina Wang</strong>, Teresa Datta, John P. Dickerson<br> 
   <em>AIES 2024</em>
</div>

<div class="paper all">
<a href="https://dl.acm.org/doi/abs/10.1145/3630106.3659045">Visions of a Discipline: Analyzing Introductory AI Courses on YouTube</a><br>
   Severin Engelmann, Madiha Zahrah Choksi, <strong>Angelina Wang</strong>, Casey Fiesler<br>
   <em>FAccT 2024</em>
</div>
                      
<div class="paper selected">
<a href="https://arxiv.org/abs/2303.06167">Overwriting Pretrained Bias with Finetuning Data</a><br>
   <strong>Angelina Wang</strong> and Olga Russakovsky<br>
   <em>ICCV 2023 <span style="color:tomato;">(Oral)</span></em>
</div>
<div class="paper all">
<a href="https://arxiv.org/abs/2206.09191">Gender Artifacts in Visual Datasets</a><br>
   Nicole Meister*, Dora Zhao*, <strong>Angelina Wang</strong>, Vikram V. Ramaswamy, Ruth Fong, Olga Russakovsky</br>
   <em>ICCV 2023</em>
</div>
<div class="paper selected">
<a href="https://dl.acm.org/doi/abs/10.1145/3636509">Against Predictive Optimization: On the Legitimacy of Decision-Making Algorithms that Optimize Predictive Accuracy</a> [<a href="https://predictive-optimization.cs.princeton.edu/">website</a>]<br>
   <strong>Angelina Wang</strong>*, Sayash Kapoor*, Solon Barocas, Arvind Narayanan</br>
   <em>FAccT 2023; Journal of Responsible Computing 2023</em>
</div>
<div class="paper all">
<a href="https://arxiv.org/abs/2305.01776">Taxonomizing and Measuring Representational Harms: A Look at Image Tagging</a><br>
   Jared Katzman*, <strong>Angelina Wang</strong>*, Morgan Scheuerman, Su Lin Blodgett, Kristen Laird, Hanna Wallach, Solon Barocas</br>
   <em>AAAI 2023</em>
</div>
<div class="paper all">
<a href="https://journals.sagepub.com/doi/10.1177/20539517221145371">Manipulative Tactics are the Norm in Political Emails: Evidence from 100K emails from the 2020 U.S. Election Cycle</a> [<a href="https://electionemails2020.org/">website</a>]<br>
   Arunesh Mathur, <strong>Angelina Wang</strong>, Carsten Schwemmer, Maia Hamin, Brandon M. Stewart, Arvind Narayanan</br>
   <em>Big Data & Society 2023</em>
</div>
<div class="paper all">
<a href="https://arxiv.org/abs/2206.07173">Measuring Representational Harms in Image Captioning
</a> [<a href="https://www.youtube.com/watch?v=WJryYsn5D3o&list=PLXA0IWa3BpHm5zXqhB9rSTJ09TiFWyMo5&index=116">4 min video</a>] [<a href="https://www.youtube.com/watch?v=P7rshiDQjDQ&list=PLXA0IWa3BpHmmS6AJN9n5Qf3ffG_eHZW0&index=116">15 min video</a>]<br>
   <strong>Angelina Wang</strong>, Solon Barocas, Kristen Laird, Hanna Wallach
</br>
   <em>FAccT 2022</em>
</div>
<div class="paper selected">
<a href="https://arxiv.org/abs/2205.04610">Towards Intersectionality in Machine Learning: Including More Identities, Handling Underrepresentation, and Performing Evaluation
</a> [<a href="https://www.youtube.com/watch?v=BkBdUK3JMXI&list=PLXA0IWa3BpHm5zXqhB9rSTJ09TiFWyMo5&index=118">4 min video</a>] [<a href="https://www.youtube.com/watch?v=wO-PIUAYMYQ&list=PLXA0IWa3BpHmmS6AJN9n5Qf3ffG_eHZW0&index=119">15 min video</a>]<br>
   <strong>Angelina Wang</strong>, Vikram V. Ramaswamy, Olga Russakovsky
</br>
   <em>FAccT 2022</em>
</div>
<div class="paper all">
<a href="https://rdcu.be/cObwT">REVISE: A Tool for Measuring and Mitigating Bias in Visual Datasets</a><br>
   <strong>Angelina Wang</strong>, Alexander Liu, Ryan Zhang, Anat Kleiman, Leslie Kim, Dora Zhao, Iroha Shirai, Arvind Narayanan, Olga Russakovsky
</br>
   <em>IJCV 2022 (extended version of ECCV 2020 publication)</em>
</div>
<div class="paper all">
<a href="https://arxiv.org/abs/2106.08503">Understanding and Evaluating Racial Biases in Image Captioning</a><br>
   Dora Zhao, <strong>Angelina Wang</strong>, Olga Russakovsky
</br>
   <em>ICCV 2021</em>
</div>
<div class="paper selected">
<a href="https://arxiv.org/abs/2102.12594">Directional Bias Amplification</a> [<a href="https://icml.cc/virtual/2021/poster/10553">video<a>] [<a href="https://docs.google.com/drawings/d/1Ed9L8t-ARv1e7wOMX8QbKsHpu4kqi866ywakUcRWN-k/edit?usp=sharing">poster<a>]<br>
   <strong>Angelina Wang</strong> and Olga Russakovsky
</br>
   <em>ICML 2021</em>
</div>
<div class="paper all">
<a href="https://arxiv.org/abs/2102.01265">The Limits of Global Inclusion in AI Development</a><br>
   Alan Chan*, Chinasa T. Okolo*, Zachary Terner*, <strong>Angelina Wang</strong>*
</br>
   <em>AAAI 2021 Workshop on Reframing Diversity in AI <span style="color:tomato;">(Spotlight)</span></em>
</div>
<div class="paper all">
<a href="https://arxiv.org/abs/2004.07999v3">REVISE: A Tool for Measuring and Mitigating Bias in Visual Datasets</a><br>
   <strong>Angelina Wang</strong>, Arvind Narayanan, Olga Russakovsky
</br>
   <em>ECCV 2020 <span style="color:tomato;">(Spotlight)</span></em>
</div>
<div class="paper all">
<a href="https://arxiv.org/abs/1905.04411">Learning Robotic Manipulation through Visual Planning and Acting</a><br>
   <strong>Angelina Wang</strong>, Thanard Kurutach, Kara Liu, Pieter Abbeel, Aviv Tamar
</br>
   <em>Robotics: Science and Systems 2019</em>
</div>
<div class="paper all">
<a href="https://arxiv.org/abs/1711.08534">Safer Classification by Synthesis</a><br>
   William Wang, <strong>Angelina Wang</strong>, Aviv Tamar, Xi Chen, Pieter Abbeel
</br>
   <em>NeurIPS 2017 Aligned AI Workshop</em>
</div>
    </div>
    </div>
    </div>
    <div class = "all">
    <h2>Other</h2>
 </div>
    <div class="paper all">
<a href="https://medium.com/@angelinaaa/a-tale-of-two-conferences-facct-and-icml-2022-a9b4eaa6cf17">A Tale of Two Conferences: FAccT and ICML 2022</a>
</div>

<script>
  const btnSelected = document.getElementById("btn-selected");
  const btnAll = document.getElementById("btn-all");
  const selectedPapers = document.querySelectorAll(".selected");
  const allPapers = document.querySelectorAll(".all");

  function showSelected() {
    selectedPapers.forEach(p => p.classList.remove("hidden"));
    allPapers.forEach(p => p.classList.add("hidden"));
    btnSelected.classList.add("active");
    btnAll.classList.remove("active");
  }

  function showAll() {
    selectedPapers.forEach(p => p.classList.remove("hidden"));
    allPapers.forEach(p => p.classList.remove("hidden"));
    btnAll.classList.add("active");
    btnSelected.classList.remove("active");
  }

  btnSelected.addEventListener("click", showSelected);
  btnAll.addEventListener("click", showAll);

  // Default to showing only selected
  showSelected();
</script>

<br><br><br><br><br><br>
    </div>
    </div>
    <script src="./website_files/bootstrap.min.js"></script>
  

</body></html>
